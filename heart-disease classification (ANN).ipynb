{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cf795df",
   "metadata": {},
   "source": [
    "## This model predicts a heart disease based on various HEALTH factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "21b7b0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the required libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6220cdfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing the data set\n",
    "\n",
    "df=pd.read_csv(\"heart-disease.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6595c606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 14)\n"
     ]
    }
   ],
   "source": [
    "#checking the dataframe shape\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3c47780c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  \n",
       "0   0     1  \n",
       "1   0     2  \n",
       "2   0     2  \n",
       "3   0     2  \n",
       "4   0     2  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making the FEATURES dataframe\n",
    "X=df.drop([\"target\"],axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9ca63a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "298    0\n",
       "299    0\n",
       "300    0\n",
       "301    0\n",
       "302    0\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making the LABELS dataframe\n",
    "Y=df[\"target\"]\n",
    "Y.tail()\n",
    "\n",
    "# label 1 indicates heart disease, label 0 indicates no heart disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f88b3528",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NORMALISING the FEATURES dataframe\n",
    "normalized_X=(X-X.min())/(X.max()-X.min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2f7f7985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.708333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.481132</td>\n",
       "      <td>0.244292</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.603053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>0.283105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.885496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.564516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>0.178082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.770992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.562500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.245283</td>\n",
       "      <td>0.251142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.816794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.245283</td>\n",
       "      <td>0.520548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.702290</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>0.262557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.396947</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.150943</td>\n",
       "      <td>0.315068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.465649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0.812500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.471698</td>\n",
       "      <td>0.152968</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.534351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>0.011416</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.335878</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>0.251142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.786260</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age  sex        cp  trestbps      chol  fbs  restecg   thalach  \\\n",
       "0    0.708333  1.0  1.000000  0.481132  0.244292  1.0      0.0  0.603053   \n",
       "1    0.166667  1.0  0.666667  0.339623  0.283105  0.0      0.5  0.885496   \n",
       "2    0.250000  0.0  0.333333  0.339623  0.178082  0.0      0.0  0.770992   \n",
       "3    0.562500  1.0  0.333333  0.245283  0.251142  0.0      0.5  0.816794   \n",
       "4    0.583333  0.0  0.000000  0.245283  0.520548  0.0      0.5  0.702290   \n",
       "..        ...  ...       ...       ...       ...  ...      ...       ...   \n",
       "298  0.583333  0.0  0.000000  0.433962  0.262557  0.0      0.5  0.396947   \n",
       "299  0.333333  1.0  1.000000  0.150943  0.315068  0.0      0.5  0.465649   \n",
       "300  0.812500  1.0  0.000000  0.471698  0.152968  1.0      0.5  0.534351   \n",
       "301  0.583333  1.0  0.000000  0.339623  0.011416  0.0      0.5  0.335878   \n",
       "302  0.583333  0.0  0.333333  0.339623  0.251142  0.0      0.0  0.786260   \n",
       "\n",
       "     exang   oldpeak  slope    ca      thal  \n",
       "0      0.0  0.370968    0.0  0.00  0.333333  \n",
       "1      0.0  0.564516    0.0  0.00  0.666667  \n",
       "2      0.0  0.225806    1.0  0.00  0.666667  \n",
       "3      0.0  0.129032    1.0  0.00  0.666667  \n",
       "4      1.0  0.096774    1.0  0.00  0.666667  \n",
       "..     ...       ...    ...   ...       ...  \n",
       "298    1.0  0.032258    0.5  0.00  1.000000  \n",
       "299    0.0  0.193548    0.5  0.00  1.000000  \n",
       "300    0.0  0.548387    0.5  0.50  1.000000  \n",
       "301    1.0  0.193548    0.5  0.25  1.000000  \n",
       "302    0.0  0.000000    0.5  0.25  0.666667  \n",
       "\n",
       "[303 rows x 13 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "df76d1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making Training and Testing data \n",
    "\n",
    "X_train,X_test,Y_train,Y_test =train_test_split(normalized_X,Y,test_size=0.2,random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a4257550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(242, 13)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f68a293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing KERAS and subsequent methods\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1fa151a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building our NEURAl NETWORK\n",
    "model=Sequential()\n",
    "\n",
    "#adding input layer and first hidden layer\n",
    "model.add(Dense(32,activation=\"relu\",input_dim=13))\n",
    "\n",
    "#adding 2nd hidden layer\n",
    "model.add(Dense(64,activation='relu'))\n",
    "\n",
    "#adding output layer\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "#compiling the ANN\n",
    "model.compile(optimizer='adam',loss=\"binary_crossentropy\",metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "facffa24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "21/21 [==============================] - 0s 544us/step - loss: 0.6729 - accuracy: 0.6116\n",
      "Epoch 2/250\n",
      "21/21 [==============================] - 0s 506us/step - loss: 0.6198 - accuracy: 0.7603\n",
      "Epoch 3/250\n",
      "21/21 [==============================] - 0s 491us/step - loss: 0.5718 - accuracy: 0.7934\n",
      "Epoch 4/250\n",
      "21/21 [==============================] - 0s 501us/step - loss: 0.5332 - accuracy: 0.7893\n",
      "Epoch 5/250\n",
      "21/21 [==============================] - 0s 483us/step - loss: 0.4904 - accuracy: 0.8058\n",
      "Epoch 6/250\n",
      "21/21 [==============================] - 0s 450us/step - loss: 0.4596 - accuracy: 0.7975\n",
      "Epoch 7/250\n",
      "21/21 [==============================] - 0s 487us/step - loss: 0.4412 - accuracy: 0.8099\n",
      "Epoch 8/250\n",
      "21/21 [==============================] - 0s 488us/step - loss: 0.4213 - accuracy: 0.8099\n",
      "Epoch 9/250\n",
      "21/21 [==============================] - 0s 499us/step - loss: 0.4093 - accuracy: 0.8306\n",
      "Epoch 10/250\n",
      "21/21 [==============================] - 0s 437us/step - loss: 0.3983 - accuracy: 0.8347\n",
      "Epoch 11/250\n",
      "21/21 [==============================] - 0s 492us/step - loss: 0.3920 - accuracy: 0.8264\n",
      "Epoch 12/250\n",
      "21/21 [==============================] - 0s 449us/step - loss: 0.3870 - accuracy: 0.8264\n",
      "Epoch 13/250\n",
      "21/21 [==============================] - 0s 465us/step - loss: 0.3788 - accuracy: 0.8347\n",
      "Epoch 14/250\n",
      "21/21 [==============================] - 0s 484us/step - loss: 0.3737 - accuracy: 0.8595\n",
      "Epoch 15/250\n",
      "21/21 [==============================] - 0s 438us/step - loss: 0.3714 - accuracy: 0.8471\n",
      "Epoch 16/250\n",
      "21/21 [==============================] - 0s 487us/step - loss: 0.3699 - accuracy: 0.8595\n",
      "Epoch 17/250\n",
      "21/21 [==============================] - 0s 494us/step - loss: 0.3665 - accuracy: 0.8595\n",
      "Epoch 18/250\n",
      "21/21 [==============================] - 0s 431us/step - loss: 0.3697 - accuracy: 0.8430\n",
      "Epoch 19/250\n",
      "21/21 [==============================] - 0s 479us/step - loss: 0.3604 - accuracy: 0.8554\n",
      "Epoch 20/250\n",
      "21/21 [==============================] - 0s 956us/step - loss: 0.3581 - accuracy: 0.8636\n",
      "Epoch 21/250\n",
      "21/21 [==============================] - 0s 489us/step - loss: 0.3546 - accuracy: 0.8554\n",
      "Epoch 22/250\n",
      "21/21 [==============================] - 0s 540us/step - loss: 0.3545 - accuracy: 0.8678\n",
      "Epoch 23/250\n",
      "21/21 [==============================] - 0s 551us/step - loss: 0.3544 - accuracy: 0.8595\n",
      "Epoch 24/250\n",
      "21/21 [==============================] - 0s 465us/step - loss: 0.3487 - accuracy: 0.8471\n",
      "Epoch 25/250\n",
      "21/21 [==============================] - 0s 511us/step - loss: 0.3437 - accuracy: 0.8636\n",
      "Epoch 26/250\n",
      "21/21 [==============================] - 0s 490us/step - loss: 0.3465 - accuracy: 0.8719\n",
      "Epoch 27/250\n",
      "21/21 [==============================] - 0s 429us/step - loss: 0.3431 - accuracy: 0.8512\n",
      "Epoch 28/250\n",
      "21/21 [==============================] - 0s 511us/step - loss: 0.3412 - accuracy: 0.8719\n",
      "Epoch 29/250\n",
      "21/21 [==============================] - 0s 498us/step - loss: 0.3341 - accuracy: 0.8719\n",
      "Epoch 30/250\n",
      "21/21 [==============================] - 0s 461us/step - loss: 0.3398 - accuracy: 0.8430\n",
      "Epoch 31/250\n",
      "21/21 [==============================] - 0s 539us/step - loss: 0.3365 - accuracy: 0.8719\n",
      "Epoch 32/250\n",
      "21/21 [==============================] - 0s 482us/step - loss: 0.3331 - accuracy: 0.8595\n",
      "Epoch 33/250\n",
      "21/21 [==============================] - 0s 440us/step - loss: 0.3268 - accuracy: 0.8678\n",
      "Epoch 34/250\n",
      "21/21 [==============================] - 0s 511us/step - loss: 0.3219 - accuracy: 0.8678\n",
      "Epoch 35/250\n",
      "21/21 [==============================] - 0s 539us/step - loss: 0.3261 - accuracy: 0.8554\n",
      "Epoch 36/250\n",
      "21/21 [==============================] - 0s 515us/step - loss: 0.3202 - accuracy: 0.8802\n",
      "Epoch 37/250\n",
      "21/21 [==============================] - 0s 438us/step - loss: 0.3200 - accuracy: 0.8636\n",
      "Epoch 38/250\n",
      "21/21 [==============================] - 0s 516us/step - loss: 0.3115 - accuracy: 0.8678\n",
      "Epoch 39/250\n",
      "21/21 [==============================] - 0s 495us/step - loss: 0.3137 - accuracy: 0.8760\n",
      "Epoch 40/250\n",
      "21/21 [==============================] - 0s 488us/step - loss: 0.3076 - accuracy: 0.8802\n",
      "Epoch 41/250\n",
      "21/21 [==============================] - 0s 552us/step - loss: 0.3037 - accuracy: 0.8802\n",
      "Epoch 42/250\n",
      "21/21 [==============================] - 0s 510us/step - loss: 0.3079 - accuracy: 0.8802\n",
      "Epoch 43/250\n",
      "21/21 [==============================] - 0s 457us/step - loss: 0.3015 - accuracy: 0.8719\n",
      "Epoch 44/250\n",
      "21/21 [==============================] - 0s 493us/step - loss: 0.2977 - accuracy: 0.8760\n",
      "Epoch 45/250\n",
      "21/21 [==============================] - 0s 490us/step - loss: 0.2946 - accuracy: 0.8802\n",
      "Epoch 46/250\n",
      "21/21 [==============================] - 0s 440us/step - loss: 0.2951 - accuracy: 0.8802\n",
      "Epoch 47/250\n",
      "21/21 [==============================] - 0s 524us/step - loss: 0.2901 - accuracy: 0.8884\n",
      "Epoch 48/250\n",
      "21/21 [==============================] - 0s 552us/step - loss: 0.2868 - accuracy: 0.8884\n",
      "Epoch 49/250\n",
      "21/21 [==============================] - 0s 482us/step - loss: 0.2858 - accuracy: 0.8926\n",
      "Epoch 50/250\n",
      "21/21 [==============================] - 0s 445us/step - loss: 0.2934 - accuracy: 0.8719\n",
      "Epoch 51/250\n",
      "21/21 [==============================] - 0s 537us/step - loss: 0.2931 - accuracy: 0.8802\n",
      "Epoch 52/250\n",
      "21/21 [==============================] - 0s 488us/step - loss: 0.2842 - accuracy: 0.8884\n",
      "Epoch 53/250\n",
      "21/21 [==============================] - 0s 441us/step - loss: 0.2730 - accuracy: 0.8926\n",
      "Epoch 54/250\n",
      "21/21 [==============================] - 0s 542us/step - loss: 0.2717 - accuracy: 0.8926\n",
      "Epoch 55/250\n",
      "21/21 [==============================] - 0s 474us/step - loss: 0.2766 - accuracy: 0.8926\n",
      "Epoch 56/250\n",
      "21/21 [==============================] - 0s 425us/step - loss: 0.2715 - accuracy: 0.8926\n",
      "Epoch 57/250\n",
      "21/21 [==============================] - 0s 478us/step - loss: 0.2677 - accuracy: 0.9008\n",
      "Epoch 58/250\n",
      "21/21 [==============================] - 0s 465us/step - loss: 0.2619 - accuracy: 0.8967\n",
      "Epoch 59/250\n",
      "21/21 [==============================] - 0s 415us/step - loss: 0.2636 - accuracy: 0.8926\n",
      "Epoch 60/250\n",
      "21/21 [==============================] - 0s 472us/step - loss: 0.2660 - accuracy: 0.8967\n",
      "Epoch 61/250\n",
      "21/21 [==============================] - 0s 433us/step - loss: 0.2576 - accuracy: 0.8967\n",
      "Epoch 62/250\n",
      "21/21 [==============================] - 0s 418us/step - loss: 0.2560 - accuracy: 0.9091\n",
      "Epoch 63/250\n",
      "21/21 [==============================] - 0s 477us/step - loss: 0.2518 - accuracy: 0.9050\n",
      "Epoch 64/250\n",
      "21/21 [==============================] - 0s 430us/step - loss: 0.2484 - accuracy: 0.9091\n",
      "Epoch 65/250\n",
      "21/21 [==============================] - 0s 485us/step - loss: 0.2483 - accuracy: 0.9091\n",
      "Epoch 66/250\n",
      "21/21 [==============================] - 0s 477us/step - loss: 0.2464 - accuracy: 0.9132\n",
      "Epoch 67/250\n",
      "21/21 [==============================] - 0s 430us/step - loss: 0.2473 - accuracy: 0.8967\n",
      "Epoch 68/250\n",
      "21/21 [==============================] - 0s 466us/step - loss: 0.2415 - accuracy: 0.9008\n",
      "Epoch 69/250\n",
      "21/21 [==============================] - 0s 549us/step - loss: 0.2385 - accuracy: 0.9174\n",
      "Epoch 70/250\n",
      "21/21 [==============================] - 0s 452us/step - loss: 0.2434 - accuracy: 0.9091\n",
      "Epoch 71/250\n",
      "21/21 [==============================] - 0s 467us/step - loss: 0.2417 - accuracy: 0.9050\n",
      "Epoch 72/250\n",
      "21/21 [==============================] - 0s 535us/step - loss: 0.2444 - accuracy: 0.9050\n",
      "Epoch 73/250\n",
      "21/21 [==============================] - 0s 452us/step - loss: 0.2355 - accuracy: 0.8967\n",
      "Epoch 74/250\n",
      "21/21 [==============================] - 0s 422us/step - loss: 0.2343 - accuracy: 0.9132\n",
      "Epoch 75/250\n",
      "21/21 [==============================] - 0s 472us/step - loss: 0.2278 - accuracy: 0.9174\n",
      "Epoch 76/250\n",
      "21/21 [==============================] - 0s 450us/step - loss: 0.2277 - accuracy: 0.9132\n",
      "Epoch 77/250\n",
      "21/21 [==============================] - 0s 533us/step - loss: 0.2303 - accuracy: 0.9132\n",
      "Epoch 78/250\n",
      "21/21 [==============================] - 0s 484us/step - loss: 0.2219 - accuracy: 0.9298\n",
      "Epoch 79/250\n",
      "21/21 [==============================] - 0s 441us/step - loss: 0.2226 - accuracy: 0.9215\n",
      "Epoch 80/250\n",
      "21/21 [==============================] - 0s 549us/step - loss: 0.2160 - accuracy: 0.9298\n",
      "Epoch 81/250\n",
      "21/21 [==============================] - 0s 481us/step - loss: 0.2252 - accuracy: 0.9215\n",
      "Epoch 82/250\n",
      "21/21 [==============================] - 0s 412us/step - loss: 0.2124 - accuracy: 0.9339\n",
      "Epoch 83/250\n",
      "21/21 [==============================] - 0s 500us/step - loss: 0.2119 - accuracy: 0.9174\n",
      "Epoch 84/250\n",
      "21/21 [==============================] - 0s 489us/step - loss: 0.2203 - accuracy: 0.9339\n",
      "Epoch 85/250\n",
      "21/21 [==============================] - 0s 424us/step - loss: 0.2091 - accuracy: 0.9215\n",
      "Epoch 86/250\n",
      "21/21 [==============================] - 0s 440us/step - loss: 0.2213 - accuracy: 0.9132\n",
      "Epoch 87/250\n",
      "21/21 [==============================] - 0s 493us/step - loss: 0.2056 - accuracy: 0.9380\n",
      "Epoch 88/250\n",
      "21/21 [==============================] - 0s 423us/step - loss: 0.2046 - accuracy: 0.9421\n",
      "Epoch 89/250\n",
      "21/21 [==============================] - 0s 440us/step - loss: 0.2019 - accuracy: 0.9339\n",
      "Epoch 90/250\n",
      "21/21 [==============================] - 0s 851us/step - loss: 0.2041 - accuracy: 0.9256\n",
      "Epoch 91/250\n",
      "21/21 [==============================] - 0s 514us/step - loss: 0.1995 - accuracy: 0.9380\n",
      "Epoch 92/250\n",
      "21/21 [==============================] - 0s 423us/step - loss: 0.2006 - accuracy: 0.9380\n",
      "Epoch 93/250\n",
      "21/21 [==============================] - 0s 469us/step - loss: 0.1938 - accuracy: 0.9380\n",
      "Epoch 94/250\n",
      "21/21 [==============================] - 0s 439us/step - loss: 0.2023 - accuracy: 0.9215\n",
      "Epoch 95/250\n",
      "21/21 [==============================] - 0s 426us/step - loss: 0.1921 - accuracy: 0.9339\n",
      "Epoch 96/250\n",
      "21/21 [==============================] - 0s 469us/step - loss: 0.1914 - accuracy: 0.9339\n",
      "Epoch 97/250\n",
      "21/21 [==============================] - 0s 424us/step - loss: 0.1941 - accuracy: 0.9339\n",
      "Epoch 98/250\n",
      "21/21 [==============================] - 0s 434us/step - loss: 0.1865 - accuracy: 0.9504\n",
      "Epoch 99/250\n",
      "21/21 [==============================] - 0s 447us/step - loss: 0.1874 - accuracy: 0.9421\n",
      "Epoch 100/250\n",
      "21/21 [==============================] - 0s 454us/step - loss: 0.1880 - accuracy: 0.9421\n",
      "Epoch 101/250\n",
      "21/21 [==============================] - 0s 492us/step - loss: 0.1822 - accuracy: 0.9504\n",
      "Epoch 102/250\n",
      "21/21 [==============================] - 0s 452us/step - loss: 0.1855 - accuracy: 0.9421\n",
      "Epoch 103/250\n",
      "21/21 [==============================] - 0s 440us/step - loss: 0.1784 - accuracy: 0.9504\n",
      "Epoch 104/250\n",
      "21/21 [==============================] - 0s 464us/step - loss: 0.1865 - accuracy: 0.9339\n",
      "Epoch 105/250\n",
      "21/21 [==============================] - 0s 444us/step - loss: 0.1844 - accuracy: 0.9380\n",
      "Epoch 106/250\n",
      "21/21 [==============================] - 0s 437us/step - loss: 0.1752 - accuracy: 0.9463\n",
      "Epoch 107/250\n",
      "21/21 [==============================] - 0s 461us/step - loss: 0.1794 - accuracy: 0.9421\n",
      "Epoch 108/250\n",
      "21/21 [==============================] - 0s 419us/step - loss: 0.1889 - accuracy: 0.9380\n",
      "Epoch 109/250\n",
      "21/21 [==============================] - 0s 473us/step - loss: 0.1717 - accuracy: 0.9587\n",
      "Epoch 110/250\n",
      "21/21 [==============================] - 0s 548us/step - loss: 0.1704 - accuracy: 0.9504\n",
      "Epoch 111/250\n",
      "21/21 [==============================] - 0s 433us/step - loss: 0.1689 - accuracy: 0.9628\n",
      "Epoch 112/250\n",
      "21/21 [==============================] - 0s 489us/step - loss: 0.1670 - accuracy: 0.9545\n",
      "Epoch 113/250\n",
      "21/21 [==============================] - 0s 550us/step - loss: 0.1652 - accuracy: 0.9504\n",
      "Epoch 114/250\n",
      "21/21 [==============================] - 0s 468us/step - loss: 0.1679 - accuracy: 0.9545\n",
      "Epoch 115/250\n",
      "21/21 [==============================] - 0s 425us/step - loss: 0.1700 - accuracy: 0.9421\n",
      "Epoch 116/250\n",
      "21/21 [==============================] - 0s 501us/step - loss: 0.1670 - accuracy: 0.9504\n",
      "Epoch 117/250\n",
      "21/21 [==============================] - 0s 436us/step - loss: 0.1627 - accuracy: 0.9504\n",
      "Epoch 118/250\n",
      "21/21 [==============================] - 0s 419us/step - loss: 0.1597 - accuracy: 0.9545\n",
      "Epoch 119/250\n",
      "21/21 [==============================] - 0s 467us/step - loss: 0.1597 - accuracy: 0.9587\n",
      "Epoch 120/250\n",
      "21/21 [==============================] - 0s 421us/step - loss: 0.1617 - accuracy: 0.9628\n",
      "Epoch 121/250\n",
      "21/21 [==============================] - 0s 468us/step - loss: 0.1700 - accuracy: 0.9380\n",
      "Epoch 122/250\n",
      "21/21 [==============================] - 0s 458us/step - loss: 0.1576 - accuracy: 0.9463\n",
      "Epoch 123/250\n",
      "21/21 [==============================] - 0s 413us/step - loss: 0.1760 - accuracy: 0.9339\n",
      "Epoch 124/250\n",
      "21/21 [==============================] - 0s 464us/step - loss: 0.1610 - accuracy: 0.9587\n",
      "Epoch 125/250\n",
      "21/21 [==============================] - 0s 446us/step - loss: 0.1582 - accuracy: 0.9545\n",
      "Epoch 126/250\n",
      "21/21 [==============================] - 0s 426us/step - loss: 0.1518 - accuracy: 0.9587\n",
      "Epoch 127/250\n",
      "21/21 [==============================] - 0s 476us/step - loss: 0.1506 - accuracy: 0.9669\n",
      "Epoch 128/250\n",
      "21/21 [==============================] - 0s 409us/step - loss: 0.1484 - accuracy: 0.9628\n",
      "Epoch 129/250\n",
      "21/21 [==============================] - 0s 489us/step - loss: 0.1486 - accuracy: 0.9587\n",
      "Epoch 130/250\n",
      "21/21 [==============================] - 0s 466us/step - loss: 0.1448 - accuracy: 0.9628\n",
      "Epoch 131/250\n",
      "21/21 [==============================] - 0s 420us/step - loss: 0.1502 - accuracy: 0.9545\n",
      "Epoch 132/250\n",
      "21/21 [==============================] - 0s 437us/step - loss: 0.1463 - accuracy: 0.9545\n",
      "Epoch 133/250\n",
      "21/21 [==============================] - 0s 458us/step - loss: 0.1440 - accuracy: 0.9669\n",
      "Epoch 134/250\n",
      "21/21 [==============================] - 0s 436us/step - loss: 0.1447 - accuracy: 0.9545\n",
      "Epoch 135/250\n",
      "21/21 [==============================] - 0s 447us/step - loss: 0.1439 - accuracy: 0.9628\n",
      "Epoch 136/250\n",
      "21/21 [==============================] - 0s 433us/step - loss: 0.1437 - accuracy: 0.9628\n",
      "Epoch 137/250\n",
      "21/21 [==============================] - 0s 440us/step - loss: 0.1421 - accuracy: 0.9587\n",
      "Epoch 138/250\n",
      "21/21 [==============================] - 0s 447us/step - loss: 0.1399 - accuracy: 0.9669\n",
      "Epoch 139/250\n",
      "21/21 [==============================] - 0s 420us/step - loss: 0.1385 - accuracy: 0.9545\n",
      "Epoch 140/250\n",
      "21/21 [==============================] - 0s 475us/step - loss: 0.1401 - accuracy: 0.9545\n",
      "Epoch 141/250\n",
      "21/21 [==============================] - 0s 460us/step - loss: 0.1468 - accuracy: 0.9380\n",
      "Epoch 142/250\n",
      "21/21 [==============================] - 0s 425us/step - loss: 0.1468 - accuracy: 0.9504\n",
      "Epoch 143/250\n",
      "21/21 [==============================] - 0s 478us/step - loss: 0.1374 - accuracy: 0.9545\n",
      "Epoch 144/250\n",
      "21/21 [==============================] - 0s 445us/step - loss: 0.1411 - accuracy: 0.9463\n",
      "Epoch 145/250\n",
      "21/21 [==============================] - 0s 421us/step - loss: 0.1398 - accuracy: 0.9628\n",
      "Epoch 146/250\n",
      "21/21 [==============================] - 0s 497us/step - loss: 0.1309 - accuracy: 0.9669\n",
      "Epoch 147/250\n",
      "21/21 [==============================] - 0s 430us/step - loss: 0.1314 - accuracy: 0.9628\n",
      "Epoch 148/250\n",
      "21/21 [==============================] - 0s 427us/step - loss: 0.1307 - accuracy: 0.9628\n",
      "Epoch 149/250\n",
      "21/21 [==============================] - 0s 470us/step - loss: 0.1357 - accuracy: 0.9628\n",
      "Epoch 150/250\n",
      "21/21 [==============================] - 0s 434us/step - loss: 0.1261 - accuracy: 0.9669\n",
      "Epoch 151/250\n",
      "21/21 [==============================] - 0s 469us/step - loss: 0.1316 - accuracy: 0.9587\n",
      "Epoch 152/250\n",
      "21/21 [==============================] - 0s 445us/step - loss: 0.1319 - accuracy: 0.9587\n",
      "Epoch 153/250\n",
      "21/21 [==============================] - 0s 413us/step - loss: 0.1282 - accuracy: 0.9669\n",
      "Epoch 154/250\n",
      "21/21 [==============================] - 0s 470us/step - loss: 0.1269 - accuracy: 0.9669\n",
      "Epoch 155/250\n",
      "21/21 [==============================] - 0s 441us/step - loss: 0.1290 - accuracy: 0.9504\n",
      "Epoch 156/250\n",
      "21/21 [==============================] - 0s 436us/step - loss: 0.1254 - accuracy: 0.9628\n",
      "Epoch 157/250\n",
      "21/21 [==============================] - 0s 474us/step - loss: 0.1235 - accuracy: 0.9628\n",
      "Epoch 158/250\n",
      "21/21 [==============================] - 0s 437us/step - loss: 0.1236 - accuracy: 0.9628\n",
      "Epoch 159/250\n",
      "21/21 [==============================] - 0s 469us/step - loss: 0.1219 - accuracy: 0.9669\n",
      "Epoch 160/250\n",
      "21/21 [==============================] - 0s 469us/step - loss: 0.1188 - accuracy: 0.9628\n",
      "Epoch 161/250\n",
      "21/21 [==============================] - 0s 475us/step - loss: 0.1221 - accuracy: 0.9628\n",
      "Epoch 162/250\n",
      "21/21 [==============================] - 0s 427us/step - loss: 0.1161 - accuracy: 0.9669\n",
      "Epoch 163/250\n",
      "21/21 [==============================] - 0s 466us/step - loss: 0.1150 - accuracy: 0.9628\n",
      "Epoch 164/250\n",
      "21/21 [==============================] - 0s 440us/step - loss: 0.1158 - accuracy: 0.9669\n",
      "Epoch 165/250\n",
      "21/21 [==============================] - 0s 415us/step - loss: 0.1130 - accuracy: 0.9669\n",
      "Epoch 166/250\n",
      "21/21 [==============================] - 0s 452us/step - loss: 0.1134 - accuracy: 0.9669\n",
      "Epoch 167/250\n",
      "21/21 [==============================] - 0s 433us/step - loss: 0.1176 - accuracy: 0.9711\n",
      "Epoch 168/250\n",
      "21/21 [==============================] - 0s 474us/step - loss: 0.1166 - accuracy: 0.9628\n",
      "Epoch 169/250\n",
      "21/21 [==============================] - 0s 429us/step - loss: 0.1117 - accuracy: 0.9669\n",
      "Epoch 170/250\n",
      "21/21 [==============================] - 0s 463us/step - loss: 0.1188 - accuracy: 0.9669\n",
      "Epoch 171/250\n",
      "21/21 [==============================] - 0s 493us/step - loss: 0.1248 - accuracy: 0.9504\n",
      "Epoch 172/250\n",
      "21/21 [==============================] - 0s 458us/step - loss: 0.1321 - accuracy: 0.9380\n",
      "Epoch 173/250\n",
      "21/21 [==============================] - 0s 416us/step - loss: 0.1089 - accuracy: 0.9587\n",
      "Epoch 174/250\n",
      "21/21 [==============================] - 0s 473us/step - loss: 0.1119 - accuracy: 0.9669\n",
      "Epoch 175/250\n",
      "21/21 [==============================] - 0s 442us/step - loss: 0.1102 - accuracy: 0.9669\n",
      "Epoch 176/250\n",
      "21/21 [==============================] - 0s 467us/step - loss: 0.1122 - accuracy: 0.9587\n",
      "Epoch 177/250\n",
      "21/21 [==============================] - 0s 452us/step - loss: 0.1075 - accuracy: 0.9669\n",
      "Epoch 178/250\n",
      "21/21 [==============================] - 0s 477us/step - loss: 0.1065 - accuracy: 0.9669\n",
      "Epoch 179/250\n",
      "21/21 [==============================] - 0s 441us/step - loss: 0.1042 - accuracy: 0.9628\n",
      "Epoch 180/250\n",
      "21/21 [==============================] - 0s 456us/step - loss: 0.1040 - accuracy: 0.9711\n",
      "Epoch 181/250\n",
      "21/21 [==============================] - 0s 440us/step - loss: 0.1018 - accuracy: 0.9711\n",
      "Epoch 182/250\n",
      "21/21 [==============================] - 0s 475us/step - loss: 0.1009 - accuracy: 0.9711\n",
      "Epoch 183/250\n",
      "21/21 [==============================] - 0s 420us/step - loss: 0.1013 - accuracy: 0.9669\n",
      "Epoch 184/250\n",
      "21/21 [==============================] - 0s 462us/step - loss: 0.1004 - accuracy: 0.9628\n",
      "Epoch 185/250\n",
      "21/21 [==============================] - 0s 492us/step - loss: 0.1007 - accuracy: 0.9711\n",
      "Epoch 186/250\n",
      "21/21 [==============================] - 0s 417us/step - loss: 0.1015 - accuracy: 0.9711\n",
      "Epoch 187/250\n",
      "21/21 [==============================] - 0s 484us/step - loss: 0.1025 - accuracy: 0.9669\n",
      "Epoch 188/250\n",
      "21/21 [==============================] - 0s 476us/step - loss: 0.0990 - accuracy: 0.9669\n",
      "Epoch 189/250\n",
      "21/21 [==============================] - 0s 457us/step - loss: 0.1092 - accuracy: 0.9628\n",
      "Epoch 190/250\n",
      "21/21 [==============================] - 0s 442us/step - loss: 0.1071 - accuracy: 0.9793\n",
      "Epoch 191/250\n",
      "21/21 [==============================] - 0s 527us/step - loss: 0.1098 - accuracy: 0.9628\n",
      "Epoch 192/250\n",
      "21/21 [==============================] - 0s 438us/step - loss: 0.1104 - accuracy: 0.9545\n",
      "Epoch 193/250\n",
      "21/21 [==============================] - 0s 489us/step - loss: 0.0963 - accuracy: 0.9711\n",
      "Epoch 194/250\n",
      "21/21 [==============================] - 0s 488us/step - loss: 0.0955 - accuracy: 0.9711\n",
      "Epoch 195/250\n",
      "21/21 [==============================] - 0s 506us/step - loss: 0.1024 - accuracy: 0.9628\n",
      "Epoch 196/250\n",
      "21/21 [==============================] - 0s 455us/step - loss: 0.1012 - accuracy: 0.9669\n",
      "Epoch 197/250\n",
      "21/21 [==============================] - 0s 554us/step - loss: 0.0940 - accuracy: 0.9711\n",
      "Epoch 198/250\n",
      "21/21 [==============================] - 0s 477us/step - loss: 0.0939 - accuracy: 0.9711\n",
      "Epoch 199/250\n",
      "21/21 [==============================] - 0s 429us/step - loss: 0.0918 - accuracy: 0.9711\n",
      "Epoch 200/250\n",
      "21/21 [==============================] - 0s 481us/step - loss: 0.1179 - accuracy: 0.9628\n",
      "Epoch 201/250\n",
      "21/21 [==============================] - 0s 465us/step - loss: 0.1028 - accuracy: 0.9669\n",
      "Epoch 202/250\n",
      "21/21 [==============================] - 0s 429us/step - loss: 0.0965 - accuracy: 0.9669\n",
      "Epoch 203/250\n",
      "21/21 [==============================] - 0s 499us/step - loss: 0.0972 - accuracy: 0.9711\n",
      "Epoch 204/250\n",
      "21/21 [==============================] - 0s 443us/step - loss: 0.0928 - accuracy: 0.9669\n",
      "Epoch 205/250\n",
      "21/21 [==============================] - 0s 444us/step - loss: 0.0916 - accuracy: 0.9752\n",
      "Epoch 206/250\n",
      "21/21 [==============================] - 0s 454us/step - loss: 0.0882 - accuracy: 0.9711\n",
      "Epoch 207/250\n",
      "21/21 [==============================] - 0s 431us/step - loss: 0.0865 - accuracy: 0.9793\n",
      "Epoch 208/250\n",
      "21/21 [==============================] - 0s 439us/step - loss: 0.0849 - accuracy: 0.9711\n",
      "Epoch 209/250\n",
      "21/21 [==============================] - 0s 491us/step - loss: 0.0867 - accuracy: 0.9711\n",
      "Epoch 210/250\n",
      "21/21 [==============================] - 0s 432us/step - loss: 0.0851 - accuracy: 0.9711\n",
      "Epoch 211/250\n",
      "21/21 [==============================] - 0s 464us/step - loss: 0.0877 - accuracy: 0.9711\n",
      "Epoch 212/250\n",
      "21/21 [==============================] - 0s 485us/step - loss: 0.0874 - accuracy: 0.9711\n",
      "Epoch 213/250\n",
      "21/21 [==============================] - 0s 443us/step - loss: 0.0838 - accuracy: 0.9711\n",
      "Epoch 214/250\n",
      "21/21 [==============================] - 0s 469us/step - loss: 0.0839 - accuracy: 0.9711\n",
      "Epoch 215/250\n",
      "21/21 [==============================] - 0s 509us/step - loss: 0.0833 - accuracy: 0.9752\n",
      "Epoch 216/250\n",
      "21/21 [==============================] - 0s 930us/step - loss: 0.0985 - accuracy: 0.9628\n",
      "Epoch 217/250\n",
      "21/21 [==============================] - 0s 481us/step - loss: 0.0873 - accuracy: 0.9752\n",
      "Epoch 218/250\n",
      "21/21 [==============================] - 0s 507us/step - loss: 0.0805 - accuracy: 0.9752\n",
      "Epoch 219/250\n",
      "21/21 [==============================] - 0s 441us/step - loss: 0.0932 - accuracy: 0.9835\n",
      "Epoch 220/250\n",
      "21/21 [==============================] - 0s 497us/step - loss: 0.0856 - accuracy: 0.9793\n",
      "Epoch 221/250\n",
      "21/21 [==============================] - 0s 473us/step - loss: 0.0901 - accuracy: 0.9587\n",
      "Epoch 222/250\n",
      "21/21 [==============================] - 0s 426us/step - loss: 0.0796 - accuracy: 0.9793\n",
      "Epoch 223/250\n",
      "21/21 [==============================] - 0s 497us/step - loss: 0.0795 - accuracy: 0.9793\n",
      "Epoch 224/250\n",
      "21/21 [==============================] - 0s 439us/step - loss: 0.0799 - accuracy: 0.9793\n",
      "Epoch 225/250\n",
      "21/21 [==============================] - 0s 468us/step - loss: 0.0760 - accuracy: 0.9793\n",
      "Epoch 226/250\n",
      "21/21 [==============================] - 0s 488us/step - loss: 0.0761 - accuracy: 0.9752\n",
      "Epoch 227/250\n",
      "21/21 [==============================] - 0s 435us/step - loss: 0.0966 - accuracy: 0.9587\n",
      "Epoch 228/250\n",
      "21/21 [==============================] - 0s 443us/step - loss: 0.0787 - accuracy: 0.9711\n",
      "Epoch 229/250\n",
      "21/21 [==============================] - 0s 461us/step - loss: 0.0873 - accuracy: 0.9711\n",
      "Epoch 230/250\n",
      "21/21 [==============================] - 0s 416us/step - loss: 0.0773 - accuracy: 0.9752\n",
      "Epoch 231/250\n",
      "21/21 [==============================] - 0s 496us/step - loss: 0.0767 - accuracy: 0.9711\n",
      "Epoch 232/250\n",
      "21/21 [==============================] - 0s 447us/step - loss: 0.0811 - accuracy: 0.9628\n",
      "Epoch 233/250\n",
      "21/21 [==============================] - 0s 450us/step - loss: 0.0749 - accuracy: 0.9752\n",
      "Epoch 234/250\n",
      "21/21 [==============================] - 0s 500us/step - loss: 0.0717 - accuracy: 0.9752\n",
      "Epoch 235/250\n",
      "21/21 [==============================] - 0s 487us/step - loss: 0.0701 - accuracy: 0.9752\n",
      "Epoch 236/250\n",
      "21/21 [==============================] - 0s 439us/step - loss: 0.0702 - accuracy: 0.9752\n",
      "Epoch 237/250\n",
      "21/21 [==============================] - 0s 451us/step - loss: 0.0714 - accuracy: 0.9793\n",
      "Epoch 238/250\n",
      "21/21 [==============================] - 0s 479us/step - loss: 0.0705 - accuracy: 0.9711\n",
      "Epoch 239/250\n",
      "21/21 [==============================] - 0s 423us/step - loss: 0.0749 - accuracy: 0.9752\n",
      "Epoch 240/250\n",
      "21/21 [==============================] - 0s 489us/step - loss: 0.0714 - accuracy: 0.9793\n",
      "Epoch 241/250\n",
      "21/21 [==============================] - 0s 479us/step - loss: 0.0686 - accuracy: 0.9793\n",
      "Epoch 242/250\n",
      "21/21 [==============================] - 0s 415us/step - loss: 0.0701 - accuracy: 0.9752\n",
      "Epoch 243/250\n",
      "21/21 [==============================] - 0s 477us/step - loss: 0.0671 - accuracy: 0.9793\n",
      "Epoch 244/250\n",
      "21/21 [==============================] - 0s 432us/step - loss: 0.0687 - accuracy: 0.9835\n",
      "Epoch 245/250\n",
      "21/21 [==============================] - 0s 428us/step - loss: 0.0674 - accuracy: 0.9793\n",
      "Epoch 246/250\n",
      "21/21 [==============================] - 0s 464us/step - loss: 0.0684 - accuracy: 0.9835\n",
      "Epoch 247/250\n",
      "21/21 [==============================] - 0s 472us/step - loss: 0.0691 - accuracy: 0.9793\n",
      "Epoch 248/250\n",
      "21/21 [==============================] - 0s 407us/step - loss: 0.0671 - accuracy: 0.9711\n",
      "Epoch 249/250\n",
      "21/21 [==============================] - 0s 432us/step - loss: 0.0703 - accuracy: 0.9752\n",
      "Epoch 250/250\n",
      "21/21 [==============================] - 0s 419us/step - loss: 0.0701 - accuracy: 0.9793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x17a7a6410>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting the model\n",
    "model.fit(X_train,Y_train,batch_size=12,epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d9b813f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 482us/step - loss: 0.0656 - accuracy: 0.9752\n",
      "loss: 0.06563737988471985 \n",
      "accuracy:  97.52066135406494\n"
     ]
    }
   ],
   "source": [
    "#train accuracy\n",
    "loss,accuracy=model.evaluate(X_train,Y_train,batch_size=12)\n",
    "print('loss:',loss,'\\n'\n",
    "     'accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3f9cb866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3876 - accuracy: 0.9180\n",
      "Test loss: 0.3875511586666107\n",
      "Test accuracy: 91.80327653884888\n"
     ]
    }
   ],
   "source": [
    "#Testing score \n",
    "score=model.evaluate(X_test,Y_test)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a2d19d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "#making predictions\n",
    "Y_preds=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8e6b3615",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting predictions to 0/1\n",
    "for i in range(0, 61) :\n",
    "    if Y_preds[i]<=0.5:\n",
    "        Y_preds[i]=0\n",
    "    else:\n",
    "        Y_preds[i]=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "18305a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[17,  4],\n",
       "       [ 1, 39]], dtype=int32)>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "cm=tf.math.confusion_matrix(Y_test,Y_preds)\n",
    "cm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "758e6f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(45.722222222222214, 0.5, 'True Value')"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualising results of ANN model\n",
    "\n",
    "import seaborn as sb\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sb.heatmap(cm,annot=True,fmt='d')\n",
    "plt.xlabel('Predicted Value')\n",
    "plt.ylabel('True Value')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
